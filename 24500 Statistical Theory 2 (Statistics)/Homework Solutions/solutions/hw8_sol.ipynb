{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "n = 30  # sample size\n",
    "x = np.arange(1, n+1) / 10  # fixed x values = 1/10 ~ n/10\n",
    "beta0 = 3   # true intercept\n",
    "alpha = 0.05  # significance level\n",
    "z = norm.ppf(1 - alpha/2)  # z_{1 - alpha/2}\n",
    "B = int(1e4)  # number of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-(a).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9530 (expected: 0.95)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)  # for reproducibility\n",
    "intervals = np.zeros((B, 2))    # to store the confidence intervals (each row is an interval)\n",
    "for b in range(B):\n",
    "    y = beta0 + np.random.randn(n)  # generate y ~ N(3, 1) = N(beta0, 1)\n",
    "    y_bar = np.mean(y)  # sample mean\n",
    "    intervals[b, 0] = y_bar - z / np.sqrt(n)  # lower bound\n",
    "    intervals[b, 1] = y_bar + z / np.sqrt(n)  # upper bound\n",
    "\n",
    "# check how many intervals contain the true value of beta0\n",
    "is_covered = (intervals[:, 0] <= beta0) & (beta0 <= intervals[:, 1])\n",
    "print(f'Coverage: {np.mean(is_covered):.4f} (expected: {1 - alpha})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-(b).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9506 (expected: 0.95)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)  # for reproducibility\n",
    "intervals = np.zeros((B, 2))    # to store the confidence intervals (each row is an interval)\n",
    "for b in range(B):\n",
    "    y = beta0 + np.random.randn(n)  # generate y ~ N(3, 1) = N(beta0, 1)\n",
    "    \n",
    "    # ols \n",
    "    x_bar = np.mean(x)\n",
    "    y_bar = np.mean(y)\n",
    "    beta_hat1 = np.sum((x - x_bar) * (y - y_bar)) / np.sum((x - x_bar)**2)\n",
    "    beta_hat0 = y_bar - beta_hat1 * x_bar\n",
    "\n",
    "    sigma = np.sqrt(1 / n + x_bar**2 / np.sum((x - x_bar)**2)) # std of beta_hat0\n",
    "    intervals[b, 0] = beta_hat0 - z * sigma\n",
    "    intervals[b, 1] = beta_hat0 + z * sigma\n",
    "\n",
    "# check how many intervals contain the true value of beta0\n",
    "is_covered = (intervals[:, 0] <= beta0) & (beta0 <= intervals[:, 1])\n",
    "print(f'Coverage: {np.mean(is_covered):.4f} (expected: {1 - alpha})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-(c).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9244 (expected: 0.95)\n",
      "Linear model valid: 0.050\n",
      "Conditional coverage when linear model is chosen: 0.4405 (expected: 0.95)\n",
      "Conditional coverage when linear model is rejected: 0.9501 (expected: 0.95)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)  # for reproducibility\n",
    "intervals = np.zeros((B, 2))    # to store the confidence intervals (each row is an interval)\n",
    "is_linear_model = np.zeros(B)  # 1 if the linear model is chosen (|beta_hat1| > threshold) and 0 otherwise\n",
    "\n",
    "for b in range(B):\n",
    "    y = beta0 + np.random.randn(n)  # generate y ~ N(3, 1) = N(beta0, 1)\n",
    "    \n",
    "    # ols \n",
    "    x_bar = np.mean(x)\n",
    "    y_bar = np.mean(y)\n",
    "    beta_hat1 = np.sum((x - x_bar) * (y - y_bar)) / np.sum((x - x_bar)**2)\n",
    "    beta_hat0 = y_bar - beta_hat1 * x_bar\n",
    "\n",
    "    if np.abs(beta_hat1) <= z / np.sqrt(np.sum((x - x_bar)**2)):\n",
    "        intervals[b, 0] = y_bar - z / np.sqrt(n)\n",
    "        intervals[b, 1] = y_bar + z / np.sqrt(n)\n",
    "\n",
    "    else:\n",
    "        is_linear_model[b] = 1\n",
    "        sigma = np.sqrt(1 / n + x_bar**2 / np.sum((x - x_bar)**2)) # std of beta_hat0\n",
    "        intervals[b, 0] = beta_hat0 - z * sigma\n",
    "        intervals[b, 1] = beta_hat0 + z * sigma\n",
    "\n",
    "# check how many intervals contain the true value of beta0\n",
    "is_covered = (intervals[:, 0] <= beta0) & (beta0 <= intervals[:, 1])\n",
    "print(f'Coverage: {np.mean(is_covered):.4f} (expected: {1 - alpha})')\n",
    "print(f'Linear model valid: {np.mean(is_linear_model):.3f}')\n",
    "print(f'Conditional coverage when linear model is chosen: {np.mean(is_covered[is_linear_model == 1]):.4f} (expected: {1 - alpha})')\n",
    "print(f'Conditional coverage when linear model is rejected: {np.mean(is_covered[is_linear_model == 0]):.4f} (expected: {1 - alpha})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-(d).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9517 (expected: 0.95)\n",
      "Linear model valid: 0.052\n",
      "Conditional coverage when linear model is chosen: 0.9540 (expected: 0.95)\n",
      "Conditional coverage when linear model is rejected: 0.9516 (expected: 0.95)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4)  # for reproducibility\n",
    "intervals = np.zeros((B, 2))    # to store the confidence intervals (each row is an interval)\n",
    "is_linear_model = np.zeros(B)  # 1 if the linear model is chosen (|beta_hat1| > threshold) and 0 otherwise\n",
    "\n",
    "for b in range(B):\n",
    "    y = beta0 + np.random.randn(n)  # generate y ~ N(3, 1) = N(beta0, 1)\n",
    "    \n",
    "    # data split (validation data = test the linear model (1 / 3), remaining data = construct the linear model (2 / 3))\n",
    "    val_id = np.random.choice(n, n // 3, replace=False)\n",
    "    rest_id = np.setdiff1d(np.arange(n), val_id)\n",
    "    x_val = x[val_id]\n",
    "    y_val = y[val_id]\n",
    "    x_rest = x[rest_id]\n",
    "    y_rest = y[rest_id]\n",
    "    n_rest = len(y_rest)\n",
    "\n",
    "    # ols with the validation data\n",
    "    x_bar = np.mean(x_val)\n",
    "    y_bar = np.mean(y_val)\n",
    "    beta_hat1 = np.sum((x_val - x_bar) * (y_val - y_bar)) / np.sum((x_val - x_bar)**2)\n",
    "    \n",
    "    if np.abs(beta_hat1) <= z / np.sqrt(np.sum((x_val - x_bar)**2)):\n",
    "        y_bar = np.mean(y_rest)\n",
    "        intervals[b, 0] = y_bar - z / np.sqrt(n_rest)\n",
    "        intervals[b, 1] = y_bar + z / np.sqrt(n_rest)\n",
    "\n",
    "    else:\n",
    "        is_linear_model[b] = 1\n",
    "\n",
    "        # ols with the remaining data\n",
    "        x_bar = np.mean(x_rest)\n",
    "        y_bar = np.mean(y_rest)\n",
    "        beta_hat1 = np.sum((x_rest - x_bar) * (y_rest - y_bar)) / np.sum((x_rest - x_bar)**2)\n",
    "        beta_hat0 = y_bar - beta_hat1 * x_bar\n",
    "        sigma = np.sqrt(1 / n_rest + x_bar**2 / np.sum((x_rest - x_bar)**2))\n",
    "        intervals[b, 0] = beta_hat0 - z * sigma\n",
    "        intervals[b, 1] = beta_hat0 + z * sigma\n",
    "\n",
    "# check how many intervals contain the true value of beta0\n",
    "is_covered = (intervals[:, 0] <= beta0) & (beta0 <= intervals[:, 1])\n",
    "print(f'Coverage: {np.mean(is_covered):.4f} (expected: {1 - alpha})')\n",
    "print(f'Linear model valid: {np.mean(is_linear_model):.3f}')\n",
    "print(f'Conditional coverage when linear model is chosen: {np.mean(is_covered[is_linear_model == 1]):.4f} (expected: {1 - alpha})')\n",
    "print(f'Conditional coverage when linear model is rejected: {np.mean(is_covered[is_linear_model == 0]):.4f} (expected: {1 - alpha})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "We have $\\hat{\\beta}_1 \\neq 0$ with probability $0.05$, which is the type I error of testing the significance of the true slope $\\beta_1 = 0$. When this happens, i.e., when we commit this type I error, the estimated intercept term $\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}$ differs much from the mean estimator $\\bar{y}$; accordingly, the interval based on $\\hat{\\beta}_0$ will not have the desired coverage probability of $0.95$.\n",
    "\n",
    "See \"conditional coverage when linear model is chosen\" in (c); the conditional coverage is significantly lower than $0.95$.\n",
    "\n",
    "On the other hand, in (d), even when we commit the type I error of testing the significance of $\\beta_1$ using the validation data, we construct the interval based on the OLS result of the remaining data independent of the validation data. In this case, the conditional coverage has to be $0.95$ even if the linear model is chosen as verified in (b)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
